
# ğŸš€ Eskalate NLP Agent

A modular, end-to-end **Natural Language Processing (NLP) agent** for information retrieval, named entity extraction, and summarization â€” designed to be **config-driven** and **dataset-agnostic**.

This project demonstrates:
- Dataset ingestion (Reuters via NLTK, Amazon Polarity via Hugging Face Datasets)
- Preprocessing & Exploratory Data Analysis (EDA)
- Rule-based and ML-based Named Entity Recognition (NER)
- Extractive summarization (TextRank)
- A configurable **agent** that retrieves, extracts, summarizes, and answers user queries.

---

## ğŸ“‚ Project Structure

```

escalate-nlp-agent/
â”œâ”€ README.md
â”œâ”€ LICENSE
â”œâ”€ requirements.txt
â”œâ”€ configs/
â”‚  â”œâ”€ config.yaml                  # Master config
â”‚  â”œâ”€ dataset/
â”‚  â”‚  â”œâ”€ reuters.yaml
â”‚  â”‚  â”œâ”€ amazon\_polarity.yaml
â”‚  â”œâ”€ extract/
â”‚  â”‚  â”œâ”€ rule\_based.yaml
â”‚  â”‚  â””â”€ spacy\_ner.yaml
â”‚  â”œâ”€ summarize/
â”‚  â”‚  â”œâ”€ textrank.yaml
â”‚  â””â”€ eval/
â”‚     â””â”€ rouge.yaml
â”œâ”€ data/                           # (gitignored)
â”‚  â”œâ”€ raw/
â”‚  â”œâ”€ interim/
â”‚  â””â”€ processed/
â”œâ”€ models/
â”‚  â”œâ”€ spacy/
â”‚  â””â”€ hf/
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01\_data\_prep\_eda.ipynb
â”‚  â”œâ”€ 02\_extraction\_demos.ipynb
â”‚  â”œâ”€ 03\_summarization\_demos.ipynb
â”‚  â””â”€ 04\_agent\_walkthrough.ipynb
â”œâ”€ reports/
â”‚  â”œâ”€ figures/
â”‚  â””â”€ brief\_report.pdf
â”œâ”€ src/
â”‚  â””â”€ escalate\_nlp\_agent/
â”‚     â”œâ”€ text\_prep/
â”‚     â”œâ”€ eda/
â”‚     â”œâ”€ extract/
â”‚     â”œâ”€ summarize/
â”‚     â”œâ”€ evaluate/
â”‚     â”œâ”€ agent/
â”‚     â””â”€ pipeline.py
â”œâ”€ scripts/
â”‚  â”œâ”€ download\_data.py
â”‚  â”œâ”€ run\_pipeline.py
â”‚  â”œâ”€ run\_extraction.py
â”‚  â”œâ”€ run\_summarization.py
â”‚  â””â”€ run\_agent\_demo.py
â””â”€ tests/

````

---

## ğŸ§  Features

- **Dataset ingestion** via configs (`configs/dataset/*.yaml`)
- **Preprocessing**: lowercase, punctuation removal, Unicode normalization, stopword removal
- **EDA**: token statistics, vocabulary frequency, NER counts
- **Extraction**:
  - Rule-based regex patterns for dates, numbers, emails, URLs
  - spaCy NER for PERSON, ORG, GPE, DATE, MONEY, PERCENT
- **Summarization**: Extractive summarization with TextRank
- **Agent**:
  - Retrieves top-k relevant documents for a query
  - Runs extractions & summarizations on retrieved docs
  - Returns synthesized final answers

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/yourusername/escalate-nlp-agent.git
cd escalate-nlp-agent
````

### 2ï¸âƒ£ Create a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

---

## ğŸ“Š Datasets

### Reuters (NLTK)

```bash
python scripts/download_data.py --dataset reuters
```

Stored under `data/raw/reuters/reuters_full.parquet`.

### Amazon Polarity (Hugging Face)

```bash
python scripts/download_data.py --dataset amazon_polarity
```

Stored under `data/raw/amazon_polarity/amazon_polarity_full.parquet`.

---

## âš™ï¸ Configuration

All dataset and pipeline settings are in `configs/`:

* `configs/dataset/reuters.yaml` â€“ Reuters dataset setup
* `configs/extract/rule_based.yaml` â€“ Regex extraction patterns
* `configs/extract/spacy_ner.yaml` â€“ spaCy model + entity labels
* `configs/summarize/textrank.yaml` â€“ TextRank parameters

---

## â–¶ï¸ Usage

### 1) Run full preprocessing + EDA

```powershell
$env:PYTHONPATH="src"
python scripts/run_pipeline.py --config configs/config.yaml
```

### 2) Run extraction

```powershell
python scripts/run_extraction.py --dataset_config configs/dataset/reuters.yaml --extract_config configs/extract/rule_based.yaml
python scripts/run_extraction.py --dataset_config configs/dataset/reuters.yaml --extract_config configs/extract/spacy_ner.yaml
```

### 3) Run summarization

```powershell
python scripts/run_summarization.py --dataset_config configs/dataset/reuters.yaml --summarize_config configs/summarize/textrank.yaml
```

### 4) Run the agent demo

```powershell
python scripts/run_agent_demo.py --dataset_config configs/dataset/reuters.yaml --agent_config configs/agent/news_aggregator.yaml --query "What did the company report about profits?"
```

---

## ğŸ““ Notebooks

* **01\_data\_prep\_eda.ipynb** â€“ Dataset loading, cleaning, token stats
* **02\_extraction\_demos.ipynb** â€“ Rule-based vs spaCy NER examples
* **03\_summarization\_demos.ipynb** â€“ Extractive summaries on sample docs
* **04\_agent\_walkthrough.ipynb** â€“ End-to-end query demonstration

---

## ğŸ“„ Example Agent Output

**Query:**

```
What did the company report about profits?
```

**Answer:**

```
craftmatic/contour industries inc said it would report substantial profits for Q1 1987...
booker plc said 1987 had started well... pretax profits rose from 46.5 mln to 54.6 mln.
```

---

## ğŸ›  Development

### Run tests

```bash
pytest tests/
```

### Lint and format

```bash
black src/ scripts/
ruff check src/ scripts/
```

---

## ğŸ”® Next Steps

* Add abstractive summarization (BART, PEGASUS)
* Improve retrieval with semantic search (e.g., SBERT embeddings)
* Deploy as an API with FastAPI/Streamlit

---

## ğŸ“œ License

MIT License â€” see [LICENSE](LICENSE) file.
