{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103999f6",
   "metadata": {},
   "source": [
    "# 04 — Agent Walkthrough (Retrieval → Extraction → Summarization → Synthesis)\n",
    "\n",
    "This notebook:\n",
    "- Loads dataset + agent configs\n",
    "- Plans a query and retrieves relevant documents (TF-IDF)\n",
    "- Runs rule-based + spaCy NER on the retrieved docs\n",
    "- Summarizes retrieved docs (extractive TextRank by default)\n",
    "- Synthesizes a final answer with evidence\n",
    "- Saves a JSON output and (optionally) writes to memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe64c457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\BAB AL SAFA\\Documents\\Vani\\personal\\escalate-nlp-agent\n",
      "Using src dir: C:\\Users\\BAB AL SAFA\\Documents\\Vani\\personal\\escalate-nlp-agent\\src\n"
     ]
    }
   ],
   "source": [
    "import os, sys, yaml, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure local package is importable (src/ layout)\n",
    "REPO_ROOT = Path.cwd().resolve().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "SRC_DIR = REPO_ROOT / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"Using src dir:\", SRC_DIR)\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc24be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NLTK Reuters | id: reuters\n",
      "Agent: News QA Agent\n"
     ]
    }
   ],
   "source": [
    "# Master config -> dataset config\n",
    "CFG_PATH = REPO_ROOT / \"configs\" / \"config.yaml\"\n",
    "with open(CFG_PATH, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "DS_CFG_PATH = REPO_ROOT / cfg[\"dataset_config\"]\n",
    "AGENT_CFG_PATH = REPO_ROOT / \"configs\" / \"agent\" / \"news_aggregator.yaml\"\n",
    "\n",
    "with open(DS_CFG_PATH, \"r\") as f:\n",
    "    ds_cfg = yaml.safe_load(f)\n",
    "with open(AGENT_CFG_PATH, \"r\") as f:\n",
    "    agent_cfg = yaml.safe_load(f)\n",
    "\n",
    "print(\"Dataset:\", ds_cfg[\"name\"], \"| id:\", ds_cfg[\"id\"])\n",
    "print(\"Agent:\", agent_cfg[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab059cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "try:\n",
    "    _ = spacy.load(\"en_core_web_sm\")\n",
    "except Exception:\n",
    "    !python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da822a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: (7616, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training/1</td>\n",
       "      <td>bahia cocoa review showers continued throughou...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training/10</td>\n",
       "      <td>computer terminal systems &amp;lt;cpml&gt; completes ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training/100</td>\n",
       "      <td>n.z. trading bank deposit growth rises slightl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text title\n",
       "0    training/1  bahia cocoa review showers continued throughou...  None\n",
       "1   training/10  computer terminal systems &lt;cpml> completes ...  None\n",
       "2  training/100  n.z. trading bank deposit growth rises slightl...  None"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_dir = REPO_ROOT / ds_cfg[\"outputs\"][\"processed_dir\"]\n",
    "train_path = proc_dir / \"train.parquet\"\n",
    "assert train_path.exists(), f\"Missing {train_path}. Run Step 1 preprocessing.\"\n",
    "\n",
    "docs = pd.read_parquet(train_path)[[\"id\",\"text\",\"title\"]]\n",
    "print(\"Docs:\", docs.shape)\n",
    "docs.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c963111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BAB AL SAFA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from escalate_nlp_agent.agent.planner import make_plan\n",
    "from escalate_nlp_agent.agent.retriever import TfidfRetriever\n",
    "from escalate_nlp_agent.agent.toolchain import run_extractors, run_summarizer, synthesize_answer\n",
    "from escalate_nlp_agent.agent.memory import remember\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e301a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plan(query='What did the company report about profits?', keywords=['what', 'did', 'the', 'company', 'report', 'about', 'profits'], need_entities=True, need_numbers=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a few examples (Reuters):\n",
    "# \"What did the company report about profits?\"\n",
    "# \"Which organizations were involved in the merger?\"\n",
    "# \"What changes happened in oil prices?\"\n",
    "QUERY = \"What did the company report about profits?\"\n",
    "\n",
    "plan = make_plan(QUERY)\n",
    "plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "092c35fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 docs in 2.71s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5478</th>\n",
       "      <td>training/6597</td>\n",
       "      <td>0.142219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>training/8163</td>\n",
       "      <td>0.118463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>training/10689</td>\n",
       "      <td>0.116421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6902</th>\n",
       "      <td>training/8861</td>\n",
       "      <td>0.116033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>training/10041</td>\n",
       "      <td>0.115332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     score\n",
       "5478   training/6597  0.142219\n",
       "6472   training/8163  0.118463\n",
       "433   training/10689  0.116421\n",
       "6902   training/8861  0.116033\n",
       "21    training/10041  0.115332"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = int(agent_cfg[\"retriever\"][\"top_k\"])\n",
    "ngram_range = tuple(agent_cfg[\"retriever\"].get(\"ngram_range\", [1,2]))\n",
    "max_features = int(agent_cfg[\"retriever\"].get(\"max_features\", 50000))\n",
    "\n",
    "t0 = time.time()\n",
    "ret = TfidfRetriever(ngram_range=ngram_range, max_features=max_features).fit(docs[[\"id\",\"text\"]])\n",
    "hits = ret.search(plan.query, top_k=top_k)\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Retrieved {len(hits)} docs in {t1 - t0:.2f}s\")\n",
    "hits[[\"id\",\"score\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18350959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Rule-based Extraction',\n",
       "  'patterns': {'dates': '\\\\b\\\\d{1,2}[/-]\\\\d{1,2}[/-]\\\\d{2,4}\\\\b',\n",
       "   'numbers': '\\\\b\\\\d+(?:\\\\.\\\\d+)?\\\\b',\n",
       "   'emails': '[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,}',\n",
       "   'urls': 'https?://[^\\\\s]+'},\n",
       "  'outputs': {'file': 'data/processed/{dataset}/extractions_rule_based.parquet'}},\n",
       " {'name': 'spaCy NER Extraction',\n",
       "  'model': 'en_core_web_sm',\n",
       "  'labels': ['PERSON', 'ORG', 'GPE', 'DATE', 'MONEY', 'PERCENT'],\n",
       "  'outputs': {'file': 'data/processed/{dataset}/extractions_spacy_ner.parquet'}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read extractor configs listed in the agent config\n",
    "extractor_cfg_paths = agent_cfg[\"extractors\"]\n",
    "\n",
    "def load_yaml(p):\n",
    "    with open(p, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "extract_cfgs = [load_yaml(REPO_ROOT / p) for p in extractor_cfg_paths]\n",
    "extract_cfgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e1fcaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD set to: C:\\Users\\BAB AL SAFA\\Documents\\Vani\\personal\\escalate-nlp-agent\n"
     ]
    }
   ],
   "source": [
    "os.chdir(REPO_ROOT)\n",
    "print(\"CWD set to:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4871d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rule_based', 'spacy_ner']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We’ll reuse the high-level runner from toolchain (which dispatches to rule-based / spaCy)\n",
    "extracts = run_extractors(hits[[\"id\",\"text\"]].copy(), extractor_cfg_paths)\n",
    "# Dictionary with keys like 'rule_based' and 'spacy_ner'\n",
    "list(extracts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f9eafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training/6597</td>\n",
       "      <td>craftmatic/contour &amp;lt;crcc&gt; sees higher profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training/8163</td>\n",
       "      <td>booker says 1987 starts well booker plc &amp;lt;bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training/10689</td>\n",
       "      <td>japan isolated, yen rises, world feels cheated...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                            summary\n",
       "0   training/6597  craftmatic/contour &lt;crcc> sees higher profi...\n",
       "1   training/8163  booker says 1987 starts well booker plc &lt;bo...\n",
       "2  training/10689  japan isolated, yen rises, world feels cheated..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_kind = agent_cfg[\"summarizer\"][\"type\"]            # \"extractive\" or \"abstractive\"\n",
    "sum_cfg_path = REPO_ROOT / agent_cfg[\"summarizer\"][\"config\"]\n",
    "\n",
    "summaries = run_summarizer(hits[[\"id\",\"text\"]].copy(), str(sum_cfg_path), sum_kind)\n",
    "summaries.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006ccc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL ANSWER ===\n",
      "\n",
      "craftmatic/contour &lt;crcc> sees higher profits craftmatic/contour industries inc said it would report substantial profits for the first quarter of fiscal 1987 ending march 31. the company recorded net income of 732,000 dlrs, or 22 cts per share, on revenues of 10.2 mln dlrs. booker says 1987 starts well booker plc &lt;bokl.l> said 1987 had started well and the group had the resources to invest in its growth business both organically and by acquisition. it was commenting on figures for 1986 which showed pretax profits rising to 54.6 mln from 46.5 mln previously.\n"
     ]
    }
   ],
   "source": [
    "answer = synthesize_answer(\n",
    "    query=plan.query,\n",
    "    docs=hits,\n",
    "    summaries=summaries,\n",
    "    extracts=extracts,\n",
    "    n_sent=int(agent_cfg[\"reasoning\"][\"answer_sentences\"])\n",
    ")\n",
    "\n",
    "print(\"=== FINAL ANSWER ===\\n\")\n",
    "print(answer[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5b70311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evidence (top retrieved docs) ---\n",
      "[training/6597] score=0.142 :: craftmatic/contour &lt;crcc> sees higher profits craftmatic/contour industries inc said it would report substantial profits for the first quarter of fiscal 1987 ending march 31. the company recorded net income of 732,000...\n",
      "[training/8163] score=0.118 :: booker says 1987 starts well booker plc &lt;bokl.l> said 1987 had started well and the group had the resources to invest in its growth business both organically and by acquisition. it was commenting on figures for 1986 w...\n",
      "[training/10689] score=0.116 :: japan isolated, yen rises, world feels cheated japan is becoming dangerously isolated again as the u.s. and europe feel they have been cheated by japanese promises to switch from export to domestic-led growth, officials ...\n",
      "[training/8861] score=0.116 :: prudential records best results in six years &lt;prudential corporation plc>, which earlier announced a 62 pct rise in 1986 pre-tax profits, said it had recorded its best general insurance result for six years but had no...\n",
      "[training/10041] score=0.115 :: volvo 1986 result off slightly from 1985 ab volvo &lt;volv.st> said the weakening dollar caused the drop in its 1986 profits, but company chief executive pehr gyllenhammar said 1986 was one of volvo's best years ever. in...\n",
      "\n",
      "--- Entities ---\n",
      "ORG: craftmatic/contour &lt;crcc>\n",
      "DATE: the first quarter of fiscal 1987 ending march 31\n",
      "ORG: cts\n",
      "DATE: 1987\n",
      "ORG: booker plc &lt;bokl.l>\n",
      "DATE: 1987\n",
      "DATE: 1986\n",
      "GPE: u.s.\n",
      "GPE: japan\n",
      "GPE: japan\n",
      "GPE: u.s.\n",
      "DATE: today\n",
      "MONEY: 145 yen\n",
      "ORG: prudential\n",
      "DATE: six years &\n",
      "\n",
      "--- Numbers/Dates by doc ---\n",
      "[training/6597] numbers=['1987', '22', '10.2', '000', '732'] dates=[]\n",
      "[training/8163] numbers=['54', '1987', '5.4', '1986', '46.5'] dates=[]\n",
      "[training/10689] numbers=['300', '145'] dates=[]\n",
      "[training/8861] numbers=['1987', '15', '178.1', '1986', '110.1'] dates=[]\n",
      "[training/10041] numbers=['86.19', '1986', '7.53', '84.09', '7.60'] dates=[]\n"
     ]
    }
   ],
   "source": [
    "def show_evidence(ans):\n",
    "    print(\"\\n--- Evidence (top retrieved docs) ---\")\n",
    "    for e in ans[\"support\"][:5]:\n",
    "        print(f\"[{e['id']}] score={e['score']:.3f} :: {e['snippet'][:220]}...\")\n",
    "\n",
    "def show_entities(ans, max_items=15):\n",
    "    ents = ans.get(\"entities\", [])[:max_items]\n",
    "    if not ents:\n",
    "        print(\"\\n(entities: none)\")\n",
    "        return\n",
    "    print(\"\\n--- Entities ---\")\n",
    "    for ent in ents:\n",
    "        print(f\"{ent['label']}: {ent['text']}\")\n",
    "\n",
    "def show_numbers_dates(ans, max_docs=5):\n",
    "    nums = ans.get(\"numbers_dates\", [])[:max_docs]\n",
    "    if not nums:\n",
    "        print(\"\\n(numbers/dates: none)\")\n",
    "        return\n",
    "    print(\"\\n--- Numbers/Dates by doc ---\")\n",
    "    for nd in nums:\n",
    "        print(f\"[{nd['id']}] numbers={nd['numbers']} dates={nd['dates']}\")\n",
    "\n",
    "show_evidence(answer)\n",
    "show_entities(answer)\n",
    "show_numbers_dates(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bacf88ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved demo JSON -> C:\\Users\\BAB AL SAFA\\Documents\\Vani\\personal\\escalate-nlp-agent\\reports\\agent\\demo_output.json\n",
      "Memory appended -> C:\\Users\\BAB AL SAFA\\Documents\\Vani\\personal\\escalate-nlp-agent\\data\\agent_memory.jsonl\n"
     ]
    }
   ],
   "source": [
    "out_json = REPO_ROOT / agent_cfg[\"outputs\"][\"demo_json\"]\n",
    "out_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_json.write_text(json.dumps(answer, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved demo JSON ->\", out_json)\n",
    "\n",
    "if agent_cfg[\"memory\"][\"enabled\"]:\n",
    "    remember(agent_cfg[\"memory\"][\"file\"], answer)\n",
    "    print(\"Memory appended ->\", REPO_ROOT / agent_cfg[\"memory\"][\"file\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47388e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japan isolated, yen rises, world feels cheated japan is becoming dangerously isolated again as the u.s. and europe feel they have been cheated by japanese promises to switch from export to domestic-led growth, officials and businessmen from around the world said. as the dollar today slipped to a rec world bank report criticises peru economic plan a confidential world bank report on the peruvian economy said the government's strategy does not offer good prospects for medium and long-term growth and is likely to quickly lead to inflation. the report, published today by an economic monthly, the pe indonesia seen at crossroads over economic change indonesia appears to be nearing a political crossroads over measures to deregulate its protected economy, the u.s.\n",
      "\n",
      "--- Evidence (top retrieved docs) ---\n",
      "[training/10689] score=0.185 :: japan isolated, yen rises, world feels cheated japan is becoming dangerously isolated again as the u.s. and europe feel they have been cheated by japanese promises to switch from export to domestic-led growth, officials ...\n",
      "[training/3351] score=0.182 :: world bank report criticises peru economic plan a confidential world bank report on the peruvian economy said the government's strategy does not offer good prospects for medium and long-term growth and is likely to quick...\n",
      "[training/237] score=0.177 :: indonesia seen at crossroads over economic change indonesia appears to be nearing a political crossroads over measures to deregulate its protected economy, the u.s. embassy says in a new report. to counter falling oil re...\n",
      "[training/10230] score=0.168 :: report says soviet economic plans too optimistic the soviet economy has grown at an increased rate under mikhail gorbachev's leadership, but his goals may be too ambitious, according to a report from u.s. intelligence ag...\n",
      "[training/11914] score=0.154 :: hog report shows more hogs on farms the usda quarterly hogs and pig report yesterday showed more hogs on u.s. farms compared to last year as profitability resulting from low grain prices encouraged producers to step up p...\n"
     ]
    }
   ],
   "source": [
    "def ask(query: str, k: int = None):\n",
    "    k = k or int(agent_cfg[\"retriever\"][\"top_k\"])\n",
    "    plan = make_plan(query)\n",
    "    hits = ret.search(plan.query, top_k=k)\n",
    "    extracts = run_extractors(hits[[\"id\",\"text\"]].copy(), agent_cfg[\"extractors\"])\n",
    "    summaries = run_summarizer(hits[[\"id\",\"text\"]].copy(), str(REPO_ROOT / agent_cfg[\"summarizer\"][\"config\"]), agent_cfg[\"summarizer\"][\"type\"])\n",
    "    return synthesize_answer(query, hits, summaries, extracts, n_sent=int(agent_cfg[\"reasoning\"][\"answer_sentences\"]))\n",
    "\n",
    "# Example:\n",
    "ans2 = ask(\"Which organizations were mentioned in the report?\")\n",
    "print(ans2[\"answer\"])\n",
    "show_evidence(ans2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8f446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
